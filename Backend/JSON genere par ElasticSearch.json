{
    "took": 143,
    "timed_out": false,
    "_shards": {
        "total": 1,
        "successful": 1,
        "skipped": 0,
        "failed": 0
    },
    "hits": {
        "total": {
            "value": 1,
            "relation": "eq"
        },
        "max_score": 0.5912616,
        "hits": [
            {
                "_index": "articles_index",
                "_id": "Y7wzcY0BFNdBWIlxOdfl",
                "_score": 0.5912616,
                "_source": {
                    "Titre": "Generating Diverse Code Explanations using the GPT-3 Large Language Model",
                    "Resume": "Good explanations are essential to efficiently learning introductory programming concepts [10]. To provide high-quality explanations at scale, numerous systems automate the process by tracing the execution of code [8, 12], defining terms [9], giving hints [16],and providing error-specific feedback [10, 16]. However, these ap-proaches often require manual effort to configure and only explain a single aspect of a given code segment. Large language models (LLMs) are also changing how students interact with code [7]. For example, Github’s Copilot can generate code for programmers [4], leading researchers to raise concerns about cheating [7]. Instead, our work focuses on LLMs’ potential to support learning by explain-ing numerous aspects of a given code snippet. This poster features a systematic analysis of the diverse natural language explanations that GPT-3 can generate automatically for a given code snippet. We present a subset of three use cases from our evolving design space of AI Explanations of Code.",
                    "TextIntegral": "To understand the types of explanations GPT-3 [2] can generate, we issued over 700 prompts across numerous code snippets. An example prompt and resulting explanation is shown in Figure 1. We discovered eight explanation types and Figure 2 includes three. explanation types to illustrate the explanatory power of GPT-3. The additional types include: 1) tracing the execution of code, 2) fixing bugs and explaining how they were fixed, 3) generating analogies to real world settings, 4) listing relevant programming concepts, and 5) predicting the console output. Instructors rate time complexity as the most difficult programming topic [17]. However, understanding time complexity is important [6, 13] because it facilitates decision-making so students choose an appropriate algorithm for a given problem. This use case shows GPT-3 can identify and explain time complexity. Commonality exists in how students solve programming prob- lems [15] and the mistakes they make [1, 11]. Pedagogical tech- niques, such as the ‘muddiest point’ highlight these common and most confusing concepts [3, 14]. GPT-3 can automatically create a checklist of common mistakes students might make regarding a given code snippet. Before understanding how a code snippet executes, it is often useful to understand the purpose of the code [5]. The summary gener- ated by GPT-3 and shown in Figure 2 defines the goal, traces theexecution, and highlights relevant CS concepts such as arrays. Our three use cases demonstrate the potential for GPT-3 to explain code for intro CS students. Our poster presentation will feature all eight explanation types as a design space of explanations to convey the diversity of explanations that can be generated by LLMs. We will highlight best practices for generating effective explanations and pitfalls that lead to less effective explanations. We are evaluating the usefulness of these explanations in a series of summer classes.",
                    "Url": "ici/le/URL",
                    "DatePublication": "2024-01-04T12:34:56.789012+00:00",
                    "estValidee": 1,
                    "Auteurs": [
                        {
                            "NomComplet": "Stephen MacNeil",
                            "Institutions": [
                                {
                                    "Nom": "Temple University Philadelphia, PA, USA",
                                    "Email": "stephen.macneil@temple.edu"
                                }
                            ]
                        },
                        {
                            "NomComplet": "Ziheng Huang",
                            "Institutions": [
                                {
                                    "Nom": "University of California—San Diego La Jolla, CA, USA",
                                    "Email": "z8huang@ucsd.edu"
                                }
                            ]
                        }
                    ],
                    "MotsCle": [
                        "large language models",
                        "natural language processing",
                        "code explana-tions",
                        "computer science education"
                    ],
                    "References": [
                        "Amjad Altadmri and Neil CC Brown. 2015. 37 million compilations: Investigatingnovice programming mistakes in large-scale student data. In Proceedings of the46th ACM Technical Symposium on Computer Science Education. 522–527.",
                        "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, AmandaAskell, et al. 2020. Language models are few-shot learners. Advances in NeuralInformation Processing Systems 33 (2020), 1877–1901.",
                        "Adam Carberry, Stephen Krause, Casey Ankeny, and Cynthia Waters. 2013.“Unmuddying” course content using muddiest point reflections. In 2013 IEEEFrontiers in Education Conference (FIE). IEEE, 937–942."
                    ]
                }
            }
        ]
    }
}